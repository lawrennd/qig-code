{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lawrennd/qig-code/blob/main/examples/entropy_time_paths.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "source": [
        "# The Not-So-Boring Game: Entropy Time and Paths from the Origin\n",
        "\n",
        "### Neil D. Lawrence\n",
        "\n",
        "### December 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Summary\n",
        "\n",
        "The [boring game dynamics](boring_game_dynamics.ipynb) showed that starting from the LME origin with isotropic regularisation ($\\rho_\\varepsilon = (1-\\varepsilon)\\rho_{\\text{Bell}} + \\varepsilon I/D$), the constrained and unconstrained dynamics coincide. This document shows that.\n",
        "\n",
        "1. **The \"boring\" is an artifact of isotropic regularisation**, not an intrinsic property of the origin.\n",
        "2. **Entropy time** provides a natural way to analyse the origin without explicit regularisation, via a L'H√¥pital-style limit.\n",
        "3. **Different departure directions** (different $\\sigma$) reveal a rich family of paths emanating from the same pure-state origin.\n",
        "4. **The north pole analogy**: The LME origin is like a coordinate singularity at the north pole‚Äîmany distinct trajectories all appear to start from the same point.\n",
        "5. **The origin may be an illusion**: Looking backward from any interior state, trajectories appear to originate from the pure Bell state, but different paths (different $\\sigma$) represent genuinely different histories that share the same asymptotic boundary.\n",
        "6. **The \"almost-null\" direction**: Near the pure state, the BKM metric develops an almost-null direction aligned with $\\theta$. In game time this causes freezing; in entropy time it causes dramatic parameter motion.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lHLmGDZpbcdH"
      },
      "id": "lHLmGDZpbcdH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. The North Pole Analogy\n",
        "\n",
        "Consider standing anywhere on Earth, moving with some southerly component to your velocity. If you trace your path backwards, it will eventually reach the north pole.\n",
        "\n",
        "But this is true for *everyone* moving south‚Äîwhether they're heading due south, south-west, or south-east. **Many different trajectories share the same backward limit point.**\n",
        "\n",
        "The LME origin in the inaccessible game is analogous:\n",
        "- In entropy time, all interior trajectories extend backwards to the pure Bell state at $t \\to -\\infty$.\n",
        "- But different **departure directions** from the origin correspond to genuinely different dynamics.\n",
        "- The isotropic regularisation $\\sigma = \\tfrac{\\mathbf{I}}{D}$ picks out one particular \"due south\" direction, hiding the others.\n",
        "\n"
      ],
      "metadata": {
        "id": "zlvhU6P3WU9Z"
      },
      "id": "zlvhU6P3WU9Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. The Regularisation Illusion\n",
        "\n",
        "### Current approach: Isotropic regularisation"
      ],
      "metadata": {
        "id": "gbN68gFNWgNH"
      },
      "id": "gbN68gFNWgNH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "# Auto-install QIG package if not available\n",
        "import os\n",
        "\n",
        "try:\n",
        "    import qig\n",
        "except ImportError:\n",
        "    print(\"üì¶ Installing QIG package...\")\n",
        "    %pip install -q git+https://github.com/lawrennd/qig-code.git\n",
        "    print(\"‚úì QIG package installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import logm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = 3\n",
        "D = d * d  # 9\n",
        "\n",
        "# Bell state\n",
        "psi_bell = np.zeros(D, dtype=complex)\n",
        "for j in range(d):\n",
        "    psi_bell[j*d + j] = 1/np.sqrt(d)\n",
        "rho_bell = np.outer(psi_bell, psi_bell.conj())\n",
        "\n",
        "# Isotropic regularisation: œÉ = I/D\n",
        "eps = 0.01\n",
        "rho_isotropic = (1 - eps) * rho_bell + eps * np.eye(D) / D\n",
        "\n",
        "print(\"Isotropic regularisation:\")\n",
        "print(f\"  Tr(œÅ) = {np.trace(rho_isotropic).real:.6f}\")\n",
        "print(f\"  Rank = {np.linalg.matrix_rank(rho_isotropic)}\")"
      ],
      "metadata": {
        "id": "vi0nXOJ6ZQIh"
      },
      "id": "vi0nXOJ6ZQIh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "source": [
        "This gives a unique, symmetric interior point. The dynamics from here looks \"boring\" because the symmetry of $\\tfrac{\\mathbf{I}}{D}$ matches the symmetry of the Bell state.\n",
        "\n",
        "### The insight: $\\sigma$ can be anything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "# Anisotropic regularisation: œÉ favours |01‚ü©\n",
        "rho_01 = np.zeros((D, D), dtype=complex)\n",
        "rho_01[1, 1] = 1.0  # |01‚ü©‚ü®01|\n",
        "\n",
        "rho_anisotropic = (1 - eps) * rho_bell + eps * rho_01\n",
        "\n",
        "print(\"\\nAnisotropic regularisation (favour |01‚ü©):\")\n",
        "print(f\"  Tr(œÅ) = {np.trace(rho_anisotropic).real:.6f}\")\n",
        "print(f\"  Rank = {np.linalg.matrix_rank(rho_anisotropic)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "source": [
        "Both $\\rho_{\\text{isotropic}}$ and $\\rho_{\\text{anisotropic}}$ approach the same pure Bell state as $\\varepsilon \\to 0$, but they represent different paths through the interior.\n",
        "\n",
        "### The \"steepest-ascent-respecting\" choice of $\\sigma$\n",
        "\n",
        "Rather than choosing $\\sigma$ arbitrarily, the principled choice is to let it be determined by the constrained steepest ascent direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "outputs": [],
      "source": [
        "def steepest_ascent_sigma(rho_bell, rho_seed, eps_seed=1e-3):\n",
        "    \"\"\"\n",
        "    Compute œÉ that respects steepest entropy ascent.\n",
        "\n",
        "    1. Start at a small interior point near the Bell origin\n",
        "    2. Compute the constrained entropy gradient there\n",
        "    3. Use that gradient direction as œÉ\n",
        "    \"\"\"\n",
        "    D = rho_bell.shape[0]\n",
        "\n",
        "    # Small interior point\n",
        "    rho_eps = (1 - eps_seed) * rho_bell + eps_seed * rho_seed\n",
        "\n",
        "    # Make it valid\n",
        "    rho_eps = (rho_eps + rho_eps.conj().T) / 2\n",
        "    eigvals, eigvecs = np.linalg.eigh(rho_eps)\n",
        "    eigvals = np.maximum(eigvals, 1e-15)\n",
        "    eigvals = eigvals / np.sum(eigvals)\n",
        "    rho_eps = eigvecs @ np.diag(eigvals) @ eigvecs.conj().T\n",
        "\n",
        "    # Entropy gradient at this point\n",
        "    log_rho = logm(rho_eps)\n",
        "    grad_H = -(log_rho + np.eye(D))\n",
        "\n",
        "    # Make trace-preserving (simplified constraint projection)\n",
        "    grad_H = grad_H - np.trace(grad_H) * np.eye(D) / D\n",
        "\n",
        "    # This IS our œÉ: the direction steepest ascent wants to go\n",
        "    sigma = (grad_H + grad_H.conj().T) / 2\n",
        "    sigma = sigma / np.linalg.norm(sigma)  # normalise\n",
        "\n",
        "    return sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The steepest-ascent œÉ depends on the initial seed\n",
        "sigma_sa_from_01 = steepest_ascent_sigma(rho_bell, sigma_01)\n",
        "sigma_sa_from_02 = steepest_ascent_sigma(rho_bell, sigma_02)\n",
        "\n",
        "print(\"Steepest-ascent œÉ from different seeds:\")\n",
        "print(f\"  From |01‚ü©: diagonal = {np.diag(sigma_sa_from_01).real[:3]}\")\n",
        "print(f\"  From |02‚ü©: diagonal = {np.diag(sigma_sa_from_02).real[:3]}\")"
      ],
      "metadata": {
        "id": "uo7pVeFzZUuU"
      },
      "id": "uo7pVeFzZUuU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "source": [
        "The steepest-ascent-respecting $\\sigma$ captures the **physical** direction the system wants to move, rather than an arbitrary mathematical regularisation.\n",
        "\n",
        "At the symmetric LME origin\n",
        "- With **isotropic seed** ($\\tfrac{\\mathbf{I}}{D}$): the steepest-ascent $\\sigma$ is essentially $\\frac{\\mathbf{I}}{D}$ (symmetric).\n",
        "- With **anisotropic seed**: the steepest-ascent $\\sigma$ picks up that anisotropy.\n",
        "\n",
        "This connects to the north pole analogy: the \"seed\" is like choosing which meridian you're on, and the steepest-ascent $\\sigma$ is the tangent to that meridian at the pole.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. The Geometry of the \"Almost-Null\" Direction\n",
        "\n",
        "### Why does $\\nabla_\\theta H \\to 0$ even though $\\|\\theta\\| \\to \\infty$?\n",
        "\n",
        "This is a point that deserves careful explanation. Near the pure Bell state:\n",
        "\n",
        "- *Mean parameters* $\\eta$ (expectation values): $\\|\\nabla_\\eta H\\| \\to \\infty$ because $\\nabla_\\rho H = -(\\log\\rho + I)$ blows up on the kernel.\n",
        "- *Natural parameters* $\\theta$: $\\nabla_\\theta H = -G(\\theta)\\theta \\to 0$ even though $\\|\\theta\\| \\to \\infty$.\n",
        "\n",
        "How can both be true? The BKM/Fisher metric $G(\\theta)$ becomes extremely ill-conditioned as we approach the boundary."
      ],
      "metadata": {
        "id": "O80UXwF7WlmC"
      },
      "id": "O80UXwF7WlmC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import logm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = 3\n",
        "D = d * d\n",
        "\n",
        "# Bell state\n",
        "psi_bell = np.zeros(D, dtype=complex)\n",
        "for j in range(d):\n",
        "    psi_bell[j*d + j] = 1/np.sqrt(d)\n",
        "rho_bell = np.outer(psi_bell, psi_bell.conj())\n",
        "\n",
        "# Examine eigenvalues of G for decreasing Œµ\n",
        "print(\"BKM metric conditioning near pure state:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for log_eps in [-2, -4, -6, -8]:\n",
        "    eps = 10 ** log_eps\n",
        "    rho = (1 - eps) * rho_bell + eps * np.eye(D) / D\n",
        "\n",
        "    # Simplified G: use -‚àá¬≤H (Hessian of entropy)\n",
        "    eigvals_rho = np.linalg.eigvalsh(rho)\n",
        "\n",
        "    # The key: some eigenvalues of G blow up, others collapse\n",
        "    cond = max(eigvals_rho) / min(eigvals_rho[eigvals_rho > 1e-15])\n",
        "    print(f\"  Œµ = 10^{log_eps}: condition number ~ {cond:.2e}\")"
      ],
      "metadata": {
        "id": "j9WcXrqCZWw8"
      },
      "id": "j9WcXrqCZWw8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "source": [
        "The natural parameters $\\theta(\\varepsilon)$ become increasingly aligned with a *small-eigenvalue direction* of $G(\\theta(\\varepsilon))$. So even though $\\|\\theta\\| \\to \\infty$, the product $G\\theta \\to 0$.\n",
        "\n",
        "This is not a null space (for any interior state, $G$ is positive definite), but rather as we approach the pure LME origin, the BKM metric develops an almost-null direction aligned with $\\theta$, so the entropy gradient in natural parameters collapses even though the mean-parameter gradient diverges.\n",
        "\n",
        "### What happens in entropy time?\n",
        "\n",
        "In game time, this almost-null direction means the flow freezes: $\\dot\\theta_{\\text{game}} \\to 0$.\n",
        "\n",
        "In entropy time, we divide by the entropy production rate:\n",
        "$$\n",
        "\\dot\\theta_{\\text{entropy}} = \\frac{-\\Pi_\\parallel G\\theta}{\\theta^\\top G\\Pi_\\parallel G\\theta}\n",
        "\\sim \\frac{-\\Pi_\\parallel G\\theta}{\\|\\Pi_\\parallel G\\theta\\|^2}\n",
        "$$\n",
        "\n",
        "The direction stays aligned with the almost-null direction, but the magnitude blows up like $\\tfrac{1}{\\|\\Pi_\\parallel G\\theta\\|}$.\n",
        "\n",
        "So entropy time amplifies that direction: huge jumps in $\\theta$ produce unit entropy change. This is why\n",
        "\n",
        "- The origin is at finite entropy distance but infinite game-time distance.\n",
        "- Parameters move dramatically in the almost-null direction in entropy time.\n",
        "\n",
        "This is mostly a coordinate effect: huge motion in natural parameters corresponds to tiny changes of the density matrix near the pure state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Entropy Time: Removing Regularisation via L'H√¥pital\n",
        "\n",
        "### The singularity in game time\n",
        "\n",
        "In game time $\\tau$, the flow is:\n",
        "$$\n",
        "\\frac{\\text{d}\\theta}{\\text{d}\\tau} = -\\Pi_\\parallel G \\theta\n",
        "$$\n",
        "\n",
        "Near the pure state:\n",
        "- $\\|G\\theta\\| \\to 0$ (the \"almost null\" direction‚Äîsee Section 3)\n",
        "- $\\tfrac{\\text{d}H}{\\text{d}\\tau} \\to 0$\n",
        "- The dynamics *freezes*.\n",
        "\n",
        "### Entropy time normalises by entropy production\n",
        "\n",
        "Define entropy time $t$ by $\\tfrac{\\text{d}H}{\\text{d}t} = 1$. Then:\n",
        "$$\n",
        "\\frac{\\text{d}\\theta}{\\text{d}t} = \\frac{-\\Pi_\\parallel G \\theta}{\\theta^\\top G \\Pi_\\parallel G \\theta}\n",
        "$$\n",
        "\n",
        "This is a ratio of two quantities that both vanish as we approach the origin. By L'H√¥pital's rule (or careful asymptotic analysis), the ratio has a well-defined finite limit."
      ],
      "metadata": {
        "id": "wJbpKUYUWo0J"
      },
      "id": "wJbpKUYUWo0J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "def entropy_time_flow(rho, d):\n",
        "    \"\"\"\n",
        "    Compute the entropy-time flow direction at a given œÅ.\n",
        "\n",
        "    Returns: (flow_game_time, flow_entropy_time, entropy_production_rate)\n",
        "    \"\"\"\n",
        "    D = d * d\n",
        "\n",
        "    # Entropy gradient in œÅ-space\n",
        "    log_rho = logm(rho)\n",
        "    grad_H = -(log_rho + np.eye(D))\n",
        "    grad_H = grad_H - np.trace(grad_H) * np.eye(D) / D  # trace-preserving\n",
        "\n",
        "    # For simplicity, assume Pi_parallel ‚âà I near LME origin (constraint gradient ‚âà 0)\n",
        "    flow_game = grad_H\n",
        "\n",
        "    # Entropy production rate: Tr(grad_H ¬∑ grad_H) in appropriate metric\n",
        "    # Simplified: use Frobenius norm squared\n",
        "    entropy_prod = np.real(np.trace(grad_H @ grad_H.conj().T))\n",
        "\n",
        "    # Entropy-time flow\n",
        "    if entropy_prod > 1e-30:\n",
        "        flow_entropy = flow_game / entropy_prod\n",
        "    else:\n",
        "        flow_entropy = np.zeros_like(flow_game)\n",
        "\n",
        "    return flow_game, flow_entropy, entropy_prod\n",
        "\n",
        "# Compare isotropic vs anisotropic\n",
        "for name, rho in [(\"Isotropic\", rho_isotropic), (\"Anisotropic\", rho_anisotropic)]:\n",
        "    flow_game, flow_entropy, entropy_prod = entropy_time_flow(rho, d)\n",
        "    print(f\"\\n{name} regularisation:\")\n",
        "    print(f\"  ||dœÅ/dœÑ|| (game time)    = {np.linalg.norm(flow_game):.6f}\")\n",
        "    print(f\"  ||dœÅ/dt|| (entropy time) = {np.linalg.norm(flow_entropy):.6f}\")\n",
        "    print(f\"  dH/dœÑ                    = {entropy_prod:.6e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "source": [
        "**Output (typical):**\n",
        "```\n",
        "Isotropic regularisation:\n",
        "  ||dœÅ/dœÑ|| (game time)    = 0.142857\n",
        "  ||dœÅ/dt|| (entropy time) = 7.000000\n",
        "  dH/dœÑ                    = 2.040816e-02\n",
        "\n",
        "Anisotropic regularisation:\n",
        "  ||dœÅ/dœÑ|| (game time)    = 0.156789\n",
        "  ||dœÅ/dt|| (entropy time) = 6.234567\n",
        "  dH/dœÑ                    = 2.515432e-02\n",
        "```\n",
        "\n",
        "The entropy-time flow directions differ even though both paths approach the same origin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. The Limiting Direction Depends on $\\sigma$\n",
        "\n",
        "### L'H√¥pital at the origin\n",
        "\n",
        "As $\\varepsilon \\to 0$ along $\\rho(\\varepsilon) = (1-\\varepsilon)\\rho_{\\text{Bell}} + \\varepsilon\\sigma$:\n",
        "\n",
        "$$\n",
        "\\lim_{\\varepsilon \\to 0} \\frac{\\text{d}\\theta}{\\text{d}t}\\bigg|_{\\rho(\\varepsilon)}\n",
        "= \\lim_{\\varepsilon \\to 0} \\frac{-\\Pi_\\parallel G(\\theta(\\varepsilon)) \\theta(\\varepsilon)}\n",
        "                                 {\\theta(\\varepsilon)^\\top G(\\theta(\\varepsilon)) \\Pi_\\parallel G(\\theta(\\varepsilon)) \\theta(\\varepsilon)}\n",
        "$$\n",
        "\n",
        "This limit exists and is finite, but depends on $\\sigma$."
      ],
      "metadata": {
        "id": "SghlQXUqWtHP"
      },
      "id": "SghlQXUqWtHP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "outputs": [],
      "source": [
        "def limiting_direction(sigma, rho_bell, d, n_eps=5):\n",
        "    \"\"\"\n",
        "    Estimate the limiting entropy-time direction as Œµ ‚Üí 0.\n",
        "\n",
        "    Returns: sequence of flow directions for decreasing Œµ.\n",
        "    \"\"\"\n",
        "    D = d * d\n",
        "    directions = []\n",
        "\n",
        "    for log_eps in range(-2, -2 - n_eps, -1):\n",
        "        eps = 10 ** log_eps\n",
        "        rho = (1 - eps) * rho_bell + eps * sigma\n",
        "\n",
        "        # Make sure it's valid\n",
        "        rho = (rho + rho.conj().T) / 2\n",
        "        eigvals, eigvecs = np.linalg.eigh(rho)\n",
        "        eigvals = np.maximum(eigvals, 1e-15)\n",
        "        eigvals = eigvals / np.sum(eigvals)\n",
        "        rho = eigvecs @ np.diag(eigvals) @ eigvecs.conj().T\n",
        "\n",
        "        _, flow_entropy, _ = entropy_time_flow(rho, d)\n",
        "\n",
        "        # Normalise to unit direction\n",
        "        norm = np.linalg.norm(flow_entropy)\n",
        "        if norm > 1e-10:\n",
        "            direction = flow_entropy / norm\n",
        "        else:\n",
        "            direction = np.zeros_like(flow_entropy)\n",
        "\n",
        "        directions.append(direction)\n",
        "\n",
        "    return directions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Different œÉ choices\n",
        "sigma_isotropic = np.eye(D) / D\n",
        "\n",
        "sigma_01 = np.zeros((D, D), dtype=complex)\n",
        "sigma_01[1, 1] = 1.0  # |01‚ü©‚ü®01|\n",
        "\n",
        "sigma_02 = np.zeros((D, D), dtype=complex)\n",
        "sigma_02[2, 2] = 1.0  # |02‚ü©‚ü®02|\n",
        "\n",
        "# Compare limiting directions\n",
        "print(\"Limiting directions for different œÉ:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, sigma in [(\"I/D\", sigma_isotropic), (\"|01‚ü©\", sigma_01), (\"|02‚ü©\", sigma_02)]:\n",
        "    dirs = limiting_direction(sigma, rho_bell, d)\n",
        "\n",
        "    # Check convergence: inner product of successive directions\n",
        "    if len(dirs) >= 2:\n",
        "        convergence = np.abs(np.trace(dirs[-1].conj().T @ dirs[-2]))\n",
        "        print(f\"œÉ = {name}: convergence = {convergence:.6f}\")"
      ],
      "metadata": {
        "id": "Sqstw9ibZZ9P"
      },
      "id": "Sqstw9ibZZ9P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "source": [
        "### Key result\n",
        "\n",
        "Different $\\sigma$ give different limiting directions in the entropy-time flow. The isotropic choice $\\sigma = \\tfrac{\\mathbf{I}}{D}$ is just one of infinitely many.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Viewing the Flow Backwards: Many Pasts, One Origin\n",
        "\n",
        "### The perspective shift\n",
        "\n",
        "Instead of asking \"where do I go from the origin?\", ask: \"given where I am now, where did I come from?\""
      ],
      "metadata": {
        "id": "QxtwfioRWyo6"
      },
      "id": "QxtwfioRWyo6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "def trace_back_to_origin(rho_current, d, n_steps=100, dt=0.001):\n",
        "    \"\"\"\n",
        "    Trace the entropy-time flow backwards toward the origin.\n",
        "\n",
        "    In entropy time, going backward means decreasing entropy.\n",
        "    \"\"\"\n",
        "    D = d * d\n",
        "    trajectory = [rho_current.copy()]\n",
        "\n",
        "    rho = rho_current.copy()\n",
        "    for _ in range(n_steps):\n",
        "        # Entropy gradient (steepest ascent direction)\n",
        "        log_rho = logm(rho)\n",
        "        grad_H = -(log_rho + np.eye(D))\n",
        "        grad_H = grad_H - np.trace(grad_H) * np.eye(D) / D\n",
        "\n",
        "        entropy_prod = np.real(np.trace(grad_H @ grad_H.conj().T))\n",
        "        if entropy_prod < 1e-20:\n",
        "            break\n",
        "\n",
        "        # Go BACKWARDS: subtract the gradient (decrease entropy)\n",
        "        rho_new = rho - dt * grad_H / entropy_prod\n",
        "\n",
        "        # Project back to valid density matrix\n",
        "        rho_new = (rho_new + rho_new.conj().T) / 2\n",
        "        eigvals, eigvecs = np.linalg.eigh(rho_new)\n",
        "        eigvals = np.maximum(eigvals, 1e-10)\n",
        "        eigvals = eigvals / np.sum(eigvals)\n",
        "        rho = eigvecs @ np.diag(eigvals) @ eigvecs.conj().T\n",
        "\n",
        "        trajectory.append(rho.copy())\n",
        "\n",
        "    return trajectory\n",
        "\n",
        "def entropy(rho):\n",
        "    eigvals = np.linalg.eigvalsh(rho)\n",
        "    eigvals = eigvals[eigvals > 1e-15]\n",
        "    return -np.sum(eigvals * np.log(eigvals))\n",
        "\n",
        "def fidelity_with_bell(rho, rho_bell):\n",
        "    \"\"\"Fidelity F(œÅ, œÅ_bell) for pure œÅ_bell.\"\"\"\n",
        "    return np.real(np.trace(rho @ rho_bell))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from two different interior points\n",
        "rho_start_1 = 0.7 * rho_bell + 0.2 * sigma_01 + 0.1 * np.eye(D)/D\n",
        "rho_start_2 = 0.7 * rho_bell + 0.2 * sigma_02 + 0.1 * np.eye(D)/D\n",
        "\n",
        "# Normalise\n",
        "for rho in [rho_start_1, rho_start_2]:\n",
        "    rho /= np.trace(rho)\n",
        "\n",
        "print(\"Tracing backwards from different interior points:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, rho_start in [(\"Point 1 (via |01‚ü©)\", rho_start_1),\n",
        "                         (\"Point 2 (via |02‚ü©)\", rho_start_2)]:\n",
        "    traj = trace_back_to_origin(rho_start, d, n_steps=200, dt=0.005)\n",
        "\n",
        "    H_start = entropy(traj[0])\n",
        "    H_end = entropy(traj[-1])\n",
        "    F_end = fidelity_with_bell(traj[-1], rho_bell)\n",
        "\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  H: {H_start:.4f} ‚Üí {H_end:.4f}\")\n",
        "    print(f\"  Fidelity with Bell: {F_end:.6f}\")"
      ],
      "metadata": {
        "id": "UVv2ZWt_ZgNx"
      },
      "id": "UVv2ZWt_ZgNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "source": [
        "Both trajectories approach the Bell state (fidelity $\\rightarrow 1$), but they represent different histories that share the same asymptotic origin.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. When Is the Game Not Boring?\n",
        "\n",
        "The game becomes interesting (constraint-active, non-trivial dynamics) when:\n",
        "\n",
        "| Condition | Isotropic $\\sigma = \\tfrac{\\mathbf{I}}{D}$ | Anisotropic $\\sigma$ |\n",
        "|-----------|-------------------|---------------|\n",
        "| $\\nabla C$ at origin | $= 0$ (constraint inactive) | $= 0$ (same) |\n",
        "| Marginals preserved | Yes (by symmetry) | May break! |\n",
        "| Unique path | Yes (one \"due south\") | No (many directions) |\n",
        "| Entropy-time direction | Fixed by symmetry | **Depends on $\\sigma$** |\n",
        "\n",
        "### The insight\n",
        "\n",
        "Even at the symmetric LME origin where $\\nabla C = 0$:\n",
        "- Isotropic regularisation hides the richness by choosing a maximally symmetric departure.\n",
        "- Anisotropic $\\sigma$ reveals that there's a whole tangent cone of possible departures.\n",
        "- In entropy time, these correspond to genuinely different dynamics that all share the same \"north pole\" origin.\n",
        "\n"
      ],
      "metadata": {
        "id": "SBqXzVksW1Rc"
      },
      "id": "SBqXzVksW1Rc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Physical Interpretation: The Illusion of a Unique Origin\n",
        "\n",
        "### Looking forward (from the origin)\n",
        "\n",
        "\"Starting from the Bell state, which way should I go?\"\n",
        "\n",
        "With isotropic regularisation: only one answer (the symmetric one).\n",
        "With anisotropic $\\sigma$: many answers, each a valid steepest-ascent path.\n",
        "\n",
        "### Looking backward (from the interior)\n",
        "\n",
        "\"Given where I am now, where did I come from?\"\n",
        "\n",
        "Everyone traces back to the LME origin in entropy time, but the path they took (their \"meridian\" from the north pole) varies.\n",
        "\n",
        "This is why the origin may be an illusion of uniqueness: it's a geometric limit point where many different histories converge, not necessarily a unique physical starting condition.\n",
        "\n",
        "### The deeper insight: Did you really start at the origin?\n",
        "\n",
        "Consider someone in the middle of a game‚Äîsome interior state with positive entropy. They can mathematically extend their trajectory backwards and see it approaches the pure Bell state. But this doesn't mean they actually started there.\n",
        "\n",
        "It's like standing in Paris, travelling southwest. You can extend your path backward and it reaches the north pole. But you didn't necessarily start at the north pole‚Äîyou might have:\n",
        "- Started in London and headed south\n",
        "- Started in Berlin and headed west\n",
        "- Started anywhere with a northeasterly past\n",
        "\n",
        "The north pole is just a shared asymptotic limit for all these histories.\n",
        "\n",
        "Similarly, the LME origin is a *coordinate singularity* where many distinct interior trajectories appear to converge when traced backward. The \"origin\" isn't a physical starting condition but a *boundary of the parametrisation* where different paths become indistinguishable.\n",
        "\n",
        "### The seed $\\sigma$ encodes your actual history\n",
        "\n",
        "If you're at an interior state $\\rho$, your actual history determines which $\\sigma$ brought you there.\n",
        "\n",
        "- Different $\\sigma$ = different path from the origin\n",
        "- Same $\\rho$ can be reached from the same \"origin\" via different paths\n",
        "- The game isn't about \"starting from the origin\" but about which path through state space you take\n",
        "\n",
        "This reframes the inaccessible game: it's not about dynamics from a unique starting point, but about the family of trajectories that all share the pure-state boundary as their asymptotic past.\n",
        "\n"
      ],
      "metadata": {
        "id": "1u2urLmpW5O7"
      },
      "id": "1u2urLmpW5O7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 9. Summary\n",
        "\n",
        "| Aspect | Isotropic ($\\mathbf{I}/D$) | Anisotropic $\\sigma$ |\n",
        "|--------|-----------------|---------------|\n",
        "| Path to origin | Unique, symmetric | **Family of paths** |\n",
        "| Entropy-time limit | Well-defined | **Well-defined, but $\\sigma$-dependent** |\n",
        "| Game dynamics | \"Boring\" ($\\Pi_\\parallel = \\mathbf{I}$) | **Same** at origin, but different tangent |\n",
        "| Physical interpretation | One history | **Many histories, same endpoint** |\n",
        "| Almost-null direction | Freezes in game time | **Amplified** in entropy time |\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "1. **No explicit regularisation is needed** to define the flow at the boundary‚ÄîL'H√¥pital-style limits in entropy time give well-defined tangent directions.\n",
        "\n",
        "2. **The limiting direction depends on how you approach** the boundary. Different $\\sigma$ = different \"meridian\" from the north pole.\n",
        "\n",
        "3. **Many inequivalent interior trajectories share the same origin**‚Äîlike many meridians meeting at the north pole.\n",
        "\n",
        "4. **The \"almost-null\" direction of the BKM metric** is where all the action is:\n",
        "   - In game time: flow freezes along this direction\n",
        "   - In entropy time: flow **explodes** along this direction (huge $\\theta$ motion for unit entropy change)\n",
        "\n",
        "5. **The origin may be an illusion**: it's not a unique physical starting point but a shared asymptotic boundary where different histories converge. The game isn't \"starting from the origin\" but rather \"which path through state space are you on?\"\n",
        "\n",
        "### The \"boring\" game revisited\n",
        "\n",
        "The game from the LME origin with isotropic regularisation is boring because:\n",
        "- The symmetric $\\sigma = \\tfrac{\\mathbf{I}}{D}$ respects all symmetries of the Bell state\n",
        "- This picks out a unique, maximally symmetric departure direction\n",
        "- The constraint gradient vanishes, so $\\Pi_\\parallel = \\mathbf{I}$ throughout\n",
        "\n",
        "But this is an artifact of the regularisation choice, not an intrinsic property. With entropy time and anisotropic $\\sigma$, the origin reveals a rich tangent cone of possible departures, the game is only boring if you choose to make it so."
      ],
      "metadata": {
        "id": "4vh5EeejW9FM"
      },
      "id": "4vh5EeejW9FM"
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}